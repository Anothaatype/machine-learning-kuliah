{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56af267b",
   "metadata": {},
   "source": [
    "## Step 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb84dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d351bb",
   "metadata": {},
   "source": [
    "## Step 2 - Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a43c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15755a04",
   "metadata": {},
   "source": [
    "## Step 3 - Explore The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1105273f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1829fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654d617",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ffa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the right column\n",
    "df = df.iloc[:, :2]\n",
    "df.columns = [\"label\", \"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc87f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3bc37",
   "metadata": {},
   "source": [
    "## Step 4 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8839bd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING DATA\n",
      "======================================================================\n",
      "\n",
      "Jumlah data training: 4457\n",
      "Jumlah data testing: 1115\n",
      "\n",
      "Distribusi kelas di training set:\n",
      "label\n",
      "0    3859\n",
      "1     598\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Mengubah label menjadi binary (ham=0, spam=1)\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "# Memisahkan fitur (X) dan target (y)\n",
    "X = df[\"message\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split data menjadi training dan testing (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nJumlah data training: {len(X_train)}\")\n",
    "print(f\"Jumlah data testing: {len(X_test)}\")\n",
    "print(f\"\\nDistribusi kelas di training set:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16380240",
   "metadata": {},
   "source": [
    "# **MODEL 1 : MULTINOMIAL NAIVE BAYES DENGAN COUNT VECTORIZER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c0a4b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 1: MULTINOMIAL NAIVE BAYES + COUNT VECTORIZER\n",
      "======================================================================\n",
      "\n",
      "Ukuran vocabulary: 7440\n",
      "Shape X_train setelah vectorization: (4457, 7440)\n",
      "Shape X_test setelah vectorization: (1115, 7440)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "EVALUASI MODEL 1 (COUNT VECTORIZER)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Accuracy:  0.9839\n",
      "Precision: 0.9580\n",
      "Recall:    0.9195\n",
      "F1-Score:  0.9384\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL 1: MULTINOMIAL NAIVE BAYES + COUNT VECTORIZER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# CountVectorizer mengubah teks menjadi matriks token count\n",
    "# stop_words='english' menghilangkan kata-kata umum seperti 'the', 'is', 'and'\n",
    "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit dan transform pada data training\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform pada data testing (hanya transform, tidak fit)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nUkuran vocabulary: {len(count_vectorizer.vocabulary_)}\")\n",
    "print(f\"Shape X_train setelah vectorization: {X_train_count.shape}\")\n",
    "print(f\"Shape X_test setelah vectorization: {X_test_count.shape}\")\n",
    "\n",
    "# Training model Multinomial Naive Bayes\n",
    "mnb_count = MultinomialNB()\n",
    "mnb_count.fit(X_train_count, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_count = mnb_count.predict(X_test_count)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"EVALUASI MODEL 1 (COUNT VECTORIZER)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "accuracy_count = accuracy_score(y_test, y_pred_count)\n",
    "precision_count = precision_score(y_test, y_pred_count)\n",
    "recall_count = recall_score(y_test, y_pred_count)\n",
    "f1_count = f1_score(y_test, y_pred_count)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy_count:.4f}\")\n",
    "print(f\"Precision: {precision_count:.4f}\")\n",
    "print(f\"Recall:    {recall_count:.4f}\")\n",
    "print(f\"F1-Score:  {f1_count:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b43f3731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[960   6]\n",
      " [ 12 137]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6196958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.99      0.99      0.99       966\n",
      "        Spam       0.96      0.92      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_count, target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f33d54",
   "metadata": {},
   "source": [
    "# **MODEL 2 : MULTINOMIAL NAIVE BAYES DENGAN TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4133d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 2: MULTINOMIAL NAIVE BAYES + TF-IDF VECTORIZER\n",
      "======================================================================\n",
      "\n",
      "Ukuran vocabulary: 7440\n",
      "Shape X_train setelah vectorization: (4457, 7440)\n",
      "Shape X_test setelah vectorization: (1115, 7440)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "EVALUASI MODEL 2 (TF-IDF VECTORIZER)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Accuracy:  0.9686\n",
      "Precision: 1.0000\n",
      "Recall:    0.7651\n",
      "F1-Score:  0.8669\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL 2: MULTINOMIAL NAIVE BAYES + TF-IDF VECTORIZER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "# Memberikan bobot lebih tinggi pada kata yang jarang muncul di banyak dokumen\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit dan transform pada data training\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform pada data testing\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nUkuran vocabulary: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "print(f\"Shape X_train setelah vectorization: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape X_test setelah vectorization: {X_test_tfidf.shape}\")\n",
    "\n",
    "# Training model Multinomial Naive Bayes\n",
    "mnb_tfidf = MultinomialNB()\n",
    "mnb_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_tfidf = mnb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"EVALUASI MODEL 2 (TF-IDF VECTORIZER)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "precision_tfidf = precision_score(y_test, y_pred_tfidf)\n",
    "recall_tfidf = recall_score(y_test, y_pred_tfidf)\n",
    "f1_tfidf = f1_score(y_test, y_pred_tfidf)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy_tfidf:.4f}\")\n",
    "print(f\"Precision: {precision_tfidf:.4f}\")\n",
    "print(f\"Recall:    {recall_tfidf:.4f}\")\n",
    "print(f\"F1-Score:  {f1_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63fb8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[966   0]\n",
      " [ 35 114]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a3089b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.97      1.00      0.98       966\n",
      "        Spam       1.00      0.77      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64972eb9",
   "metadata": {},
   "source": [
    "# Conclusion Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02d55e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERBANDINGAN MODEL\n",
      "======================================================================\n",
      "\n",
      "    Metric  CountVectorizer   TF-IDF\n",
      " Accuracy         0.983857 0.968610\n",
      "Precision         0.958042 1.000000\n",
      "   Recall         0.919463 0.765101\n",
      " F1-Score         0.938356 0.866920\n",
      "\n",
      "Selisih Performance (TF-IDF - CountVectorizer):\n",
      "Accuracy:  -0.0152\n",
      "Precision: 0.0420\n",
      "Recall:    -0.1544\n",
      "F1-Score:  -0.0714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PERBANDINGAN MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"],\n",
    "    \"CountVectorizer\": [accuracy_count, precision_count, recall_count, f1_count],\n",
    "    \"TF-IDF\": [accuracy_tfidf, precision_tfidf, recall_tfidf, f1_tfidf],\n",
    "})\n",
    "\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "# Menghitung selisih\n",
    "print(\"\\nSelisih Performance (TF-IDF - CountVectorizer):\")\n",
    "print(f\"Accuracy:  {(accuracy_tfidf - accuracy_count):.4f}\")\n",
    "print(f\"Precision: {(precision_tfidf - precision_count):.4f}\")\n",
    "print(f\"Recall:    {(recall_tfidf - recall_count):.4f}\")\n",
    "print(f\"F1-Score:  {(f1_tfidf - f1_count):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a84d8",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "KESIMPULAN\n",
      "======================================================================\n",
      "\n",
      "Berdasarkan hasil evaluasi pada dataset spam.csv:\n",
      "\n",
      "1. MODEL TERBAIK: Count Vectorizer\n",
      "   - Memiliki accuracy lebih tinggi sebesar 0.0152 (1.52%)\n",
      "\n",
      "2. PENJELASAN:\n",
      "   a) Count Vectorizer:\n",
      "      - Menghitung frekuensi kemunculan kata\n",
      "      - Sederhana dan cepat\n",
      "      - Cocok untuk dataset kecil atau kata yang frekuensinya penting\n",
      "\n",
      "   b) TF-IDF Vectorizer:\n",
      "      - Memberikan bobot berdasarkan kepentingan kata\n",
      "      - Mengurangi pengaruh kata yang terlalu umum\n",
      "      - Lebih baik untuk menangkap kata-kata unik yang membedakan spam/ham\n",
      "\n",
      "3. ALASAN PERBEDAAN PERFORMA:\n",
      "   - Spam biasanya mengandung kata-kata spesifik yang jarang (misal: \"winner\", \"free\", \"claim\")\n",
      "   - TF-IDF memberikan bobot lebih tinggi pada kata-kata unik ini\n",
      "   - Count Vectorizer memperlakukan semua kata sama, kurang sensitif terhadap kata kunci spam\n",
      "\n",
      "4. REKOMENDASI:\n",
      "   - Untuk deteksi spam, gunakan Count Vectorizer\n",
      "   - Pertimbangkan juga parameter tuning untuk optimasi lebih lanjut\n",
      "   - Monitor false positive/negative sesuai kebutuhan bisnis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KESIMPULAN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if accuracy_tfidf > accuracy_count:\n",
    "    best_model = \"TF-IDF Vectorizer\"\n",
    "    accuracy_diff = accuracy_tfidf - accuracy_count\n",
    "else:\n",
    "    best_model = \"Count Vectorizer\"\n",
    "    accuracy_diff = accuracy_count - accuracy_tfidf\n",
    "\n",
    "print(f\"\"\"\n",
    "Berdasarkan hasil evaluasi pada dataset spam.csv:\n",
    "\n",
    "1. MODEL TERBAIK: {best_model}\n",
    "   - Memiliki accuracy lebih tinggi sebesar {accuracy_diff:.4f} ({accuracy_diff * 100:.2f}%)\n",
    "   \n",
    "2. PENJELASAN:\n",
    "   a) Count Vectorizer:\n",
    "      - Menghitung frekuensi kemunculan kata\n",
    "      - Sederhana dan cepat\n",
    "      - Cocok untuk dataset kecil atau kata yang frekuensinya penting\n",
    "      \n",
    "   b) TF-IDF Vectorizer:\n",
    "      - Memberikan bobot berdasarkan kepentingan kata\n",
    "      - Mengurangi pengaruh kata yang terlalu umum\n",
    "      - Lebih baik untuk menangkap kata-kata unik yang membedakan spam/ham\n",
    "      \n",
    "3. ALASAN PERBEDAAN PERFORMA:\n",
    "   - Spam biasanya mengandung kata-kata spesifik yang jarang (misal: \"winner\", \"free\", \"claim\")\n",
    "   - TF-IDF memberikan bobot lebih tinggi pada kata-kata unik ini\n",
    "   - Count Vectorizer memperlakukan semua kata sama, kurang sensitif terhadap kata kunci spam\n",
    "   \n",
    "4. REKOMENDASI:\n",
    "   - Untuk deteksi spam, gunakan {best_model}\n",
    "   - Pertimbangkan juga parameter tuning untuk optimasi lebih lanjut\n",
    "   - Monitor false positive/negative sesuai kebutuhan bisnis\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40292d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-kuliah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
